# ABS-CDSS: Akademischer Fließtext zur Systemarchitektur und Implementierung

Das hier beschriebene Clinical Decision Support System (CDSS) zielt auf die initiale empirische Antibiotikatherapie im Erwachsenenalter ab und verbindet drei komplementäre Säulen: erstens ein Retrieval-Augmented-Generation-Verfahren (RAG) auf Basis deutschsprachiger Leitlinieninhalte einschließlich spezifischer Dosistabellen, zweitens die Integration von Patientendaten gemäß HL7® FHIR® (R4B) und drittens den Einsatz eines generativen Sprachmodells (LLM) mit einer streng strukturierten, JSON-basierten Ergebnisrepräsentation. Diese Trias ermöglicht es, kontextualisierte, nachvollziehbare und evidenzbasierte Therapieempfehlungen zu erzeugen, in denen pharmakologische Details (Dosierung, Frequenz, Applikationsweg und Therapiedauer) ebenso präsent sind wie klinische Leitlinienhinweise, Sicherheitsaspekte und patientenindividuelle Faktoren.

Aus architektonischer Perspektive bildet ein Python-Backend auf Basis von FastAPI das Orchestrierungszentrum. Es exponiert REST-Endpunkte – optional auch als Server-Sent Events (SSE) für schrittweise Fortschrittsmeldungen – und kapselt die Domänenlogiken für RAG, FHIR-Zugriffe, LLM-Aufrufe sowie Persistenz. Die Gesamtlogik verteilt sich auf klar getrennte Module: In `main.py` werden die API-Endpunkte definiert, das Streaming koordiniert und die Frontend-Bundles ausgeliefert. Die RAG-Pipeline ist in `rag_service_advanced.py` realisiert und umfasst das Einlesen von Leitlinien, ein überlappungsbewusstes Markdown-Chunking, die Vektorisierung per lokalem oder online-basiertem Embedding-Service und die Indexierung mittels FAISS. Zentraler Bestandteil ist die strukturierte Query-Konstruktion, die klinische Suchintentionen in drei Ebenen abbildet: MUST-Komponenten (z. B. Indikationssynonyme und Schweregrad), SHOULD-Komponenten (z. B. Risikofaktoren, Infektionslokalisation, Verdachtskeime und Freitext) sowie BOOST-Anker (Begriffe wie „Therapie“, „Dosierung“, „Tabelle“ und „Dauer“), die das Ranking gezielt beeinflussen. Negativ-Booster wurden bewusst entfernt, da sie sich in realen Daten als fragil erwiesen. Die Suche kombiniert semantische Ähnlichkeit im FAISS-Vektorraum mit lexikalischen Boost-Faktoren, wodurch Abschnitte mit hoher thematischer Passung und terminologischer Nähe priorisiert werden.

Eine Besonderheit stellt die separierte Behandlung von Dosistabellen dar. Die Datei `dosis_tabellen.md` wird in HTML-Strukturen zerlegt, tabellarische Inhalte werden in LLM-optimierte, flache Textrepräsentationen überführt, und ein eigenständiger FAISS-Index über Tabellennamen ermöglicht eine gezielte Abfrage. Für Dosistabellen greift eine spezialisierte Suchphrase, die Indikations- und Dosisbezüge stark gewichtet. Das Ergebnis sind wenige, klinisch prägnante Tabellenpassagen, deren Relevanzwerte normalisiert und zusammen mit den Fließtextpassagen an die Kontexterzeugung weitergereicht werden. Diese Kontexterzeugung übernimmt der `TherapyContextBuilder` und integriert neben den RAG-Treffern die individuellen Patientendaten sowie zusätzliche Wissensbausteine (z. B. Sicherheit/Verträglichkeit, Altersaspekte, multiresistente Erreger, renale Dosisanpassungen). Der Builder formatiert einen kohärenten, für Sprachmodelle optimierten Prompttext, der die klinische Ausgangslage, die patientenbezogenen Parameter, die evidenzbasierten Leitlinienauszüge und die Dosistabellen in klar gegliederten Abschnitten zusammenführt.

Die Patientenseite stützt sich auf einen FHIR-Service, der gegen eine HAPI-FHIR-Instanz in der R4B-Spezifikation arbeitet. Neben der Suche nach Patientinnen und Patienten (über ID oder über Name und Geburtsdatum) werden Bündel relevanter Ressourcen zusammengetragen, darunter Condition, Observation, MedicationStatement, AllergyIntolerance und die aufgelösten Medication-Objekte. Da FHIR-Datenqualität und -Konsistenz variieren können, verwendet die Implementierung mehrere Pfade der Validierung und des Parsings (verschiedene Pydantic-Konstruktoren sowie einen rohformatigen Fallback), um robuste Extrakte zu erhalten. Im Fokus stehen klinisch essenzielle Attribute wie Alter, Geschlecht, geschätzte glomeruläre Filtrationsrate (eGFR), Hinweise auf Schwangerschaft, laborchemische Marker, Medikation und Allergien – jeweils so aufbereitet, dass sie die RAG-Auswahl und die nachfolgende Dosisbegründung sinnvoll beeinflussen.

Die generative Schlussfolgerungsschicht basiert auf einem OpenAI-kompatiblen API-Zugang über Novita AI. Die Systeminstruktion ist bewusst strikt gehalten und erzwingt eine deutschsprachige, rein JSON-basierte Antwortstruktur, in der Therapieoptionen als Liste von Wirkstoffen mit Dosisintervallen, Einheiten, Frequenzen und standardisierter Therapiedauer erscheinen. Ergänzend enthält die Antwort eine strukturierte klinische Begründung sowie Quellenzitate mit Originaltitel, Jahr und Passagenangaben. Durch das von der API unterstützte `response_format` wird die Wahrscheinlichkeit fehlerhafter Freitexte reduziert; dennoch säubert die Implementierung die Antworten defensiv und extrahiert im Zweifel die valide JSON-Teilmenge. Die resultierenden Objekte werden mittels Pydantic validiert und dem Frontend mit zusätzlichen Debug-Informationen (z. B. verwendetem Prompt, Modellparametern) zur Verfügung gestellt.

Aus Anwendersicht stehen zwei Frontends bereit. Das Enduser-Frontend, gestaltet mit Material UI und React Router, fokussiert die klinische Nutzung: ein strukturiertes Therapieanfrageformular, die Anzeige der resultierenden Empfehlungen einschließlich der patientenbezogenen Zusammenfassung sowie eine Funktion zur Speicherung und späteren Einsicht. Für langlaufende Anfragen ist optional ein Streamingmodus vorgesehen, der Fortschrittsnachrichten als SSE übermittelt und so typische Timeout-Beschränkungen in Cloud-Umgebungen entschärft. Das Admin-Frontend dient dem Hochladen und der Verwaltung von Leitlinien, der Analyse der Suchphrasen (inklusive Sicht auf MUST/SHOULD/BOOST-Komponenten), dem Testen der FHIR-Schnittstellen sowie der allgemeinen Systemdiagnostik. Beide Frontends werden in einer Docker-Multi-Stage-Pipeline erzeugt: Im ersten Schritt baut eine Node-Umgebung getrennte Bundles für Admin (unter `/admin`) und Enduser (unter `/`), im zweiten werden diese Bundles mit dem Python-Backend in ein minimales Runtime-Image integriert. Die Koyeb-Deployment-Konfiguration definiert Ressourcenbudgets, Healthchecks, öffentlich zugängliche Ports und sämtliche benötigten Umgebungsvariablen – insbesondere für die Wahl des Embedding-Pfads (lokal vs. online), das Throttling von Embedding-Anfragen sowie die LLM-Endpunkte und Modelle.

Robustheit ist auf mehreren Ebenen adressiert. Die RAG-Komponente kombiniert semantische Scores mit lexikalischen Boosts, um sachlich passende und terminologisch präzise Passagen zu priorisieren. Der FHIR-Service nutzt redundante Parsingpfade und bereinigt Eingaben, um Validierungsfehler abzufangen. Die LLM-Schicht stützt sich auf strikte Schemata, die sowohl die maschinelle Validierbarkeit als auch die klinische Lesbarkeit sichern. Frontend-seitig helfen Streaming-Keep-Alives und großzügigere Zeitlimits, Netzwerk- und Plattformbeschränkungen zu überbrücken. Debug-Endpunkte, detaillierte Logs und optionale Metriken vereinfachen die Diagnose von Fehlverhalten. In Summe entsteht ein System, das bei begrenzten Ressourcen eine balancierte Kombination aus Evidenzorientierung, Patientenzentrierung und operativer Zuverlässigkeit anstrebt.

Aus wissenschaftlicher Sicht ist insbesondere die Query-Konstruktion hervorzuheben, die klinische Sachverhalte in eine gewichtete, mehrschichtige Suchrepräsentation überführt und dabei eine Brücke zwischen kontrollierten Vokabularen (Indikationssynonyme, LOINC-Codes) und freiem klinischem Ausdruck schlägt. Diese Kopplung – zusammen mit der gesonderten Behandlung von Dosistabellen – verbessert die Wahrscheinlichkeit, dass der generative Teil der Pipeline auf präzise, therapietaugliche Evidenz referenziert. Gleichzeitig schafft die strenge JSON-Spezifikation einen Prüfpunkthaken, der die nachgelagerte, deterministische Weiterverarbeitung der Therapieoptionen ermöglicht, etwa für UI-Darstellungen, Validierungsroutinen oder das Speichern und spätere Abrufen der Empfehlungen. Perspektivisch bieten sich Erweiterungen an: die Ergänzung eines hybriden Retrievals (BM25 + Vektorraum), die Ausweitung des LOINC- und SNOMED-Mappings im FHIR-Parser, SMART-on-FHIR-basierte Authentifizierungsflüsse für produktive Klinikinfrastrukturen sowie eine noch stärkere formale Spezifikation der JSON-Schemata (z. B. Draft 2020‑12) für automatisierte Konformitätsprüfungen. Schließlich könnte ein systematisches Offline-Evaluationsprotokoll für die Query-Qualität und die Übereinstimmung der LLM-Antworten mit den zitierten Quellen die wissenschaftliche Validität weiter festigen.
